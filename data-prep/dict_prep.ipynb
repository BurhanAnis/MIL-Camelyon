{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_list_of_paths, load_data, save_data\n",
    "from wsi_prep import get_tissue_mask, get_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_coords_neg = load_data('tile_coords_neg.pkl')\n",
    "tile_coords_pos = load_data('tile_coords_pos.pkl')\n",
    "tile_coords_test = load_data('tile_coords_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_neg = '/Volumes/BurhanAnisExtDrive/camelyon/camelyon_data/training/negative'\n",
    "paths_pos = '/Volumes/BurhanAnisExtDrive/camelyon/camelyon_data/training/positive/images'\n",
    "paths_test = '/Volumes/BurhanAnisExtDrive/camelyon/camelyon_data/test/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg = get_list_of_paths(paths_neg)\n",
    "train_pos = get_list_of_paths(paths_pos)\n",
    "test = get_list_of_paths(paths_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"slides\": train_neg + train_pos,  # Combine slide paths\n",
    "    \"grid\": tile_coords_neg + tile_coords_pos,  # Combine tile coordinates\n",
    "    \"targets\": [0] * len(train_neg) + [1] * len(train_pos),  # Generate targets\n",
    "    \"mult\": 1.0,  # Scaling factor (constant for all slides)\n",
    "    \"level\": 0    # Resolution level (constant for all slides)\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(data, \"data.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved training data from 'train.pth'\n",
    "dict = torch.load('data.pth')\n",
    "\n",
    "# Extract only the first 10 slides, grids, and targets\n",
    "train_dict = {\n",
    "    \"slides\": dict[\"slides\"][:10],  # First 10 slide paths\n",
    "    \"grid\": dict[\"grid\"][:10],      # First 10 tile coordinate lists\n",
    "    \"targets\": dict[\"targets\"][:10], # First 10 targets\n",
    "    \"mult\": dict[\"mult\"],           # Keep scaling factor as is\n",
    "    \"level\": dict[\"level\"]          # Keep resolution level as is\n",
    "}\n",
    "\n",
    "val_dict = {\n",
    "    \"slides\": dict[\"slides\"][10:15],  # First 10 slide paths\n",
    "    \"grid\": dict[\"grid\"][10:15],      # First 10 tile coordinate lists\n",
    "    \"targets\": dict[\"targets\"][10:15], # First 10 targets\n",
    "    \"mult\": dict[\"mult\"],           # Keep scaling factor as is\n",
    "    \"level\": dict[\"level\"]          # Keep resolution level as is\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dict, 'train.pth')\n",
    "torch.save(val_dict, 'val.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
